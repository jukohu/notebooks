{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install Packages that are required for this procedure\n",
    "\n",
    "\n",
    "!pip install selenium pandas openpyxl requests os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######\n",
    "\n",
    "# 1. Step: Automized download of all excel files (February 2020 - February 2025) from the BA website (https://statistik.arbeitsagentur.de/SiteGlobals/Forms/Suche/Einzelheftsuche_Formular.html?topic_f=analyse-gemeldete-arbeitsstellen-kldb2010)\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# === Load Packages ===\n",
    "\n",
    "from selenium import webdriver # Selenium is used for the automatic download of files from the web browser\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "# === Setup Edge ===\n",
    "\n",
    "# The microsoft edge driver is required for selenium to work. This code opens the microsoft edge driver:\n",
    "service = Service(\"C:\\\\Users\\\\jhummels\\\\OneDrive - DIW Berlin\\\\Gehlen, Annica's files - retirement-labor-shortages\\\\edgedriver\\\\msedgedriver.exe\")\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Edge(service=service, options=options)\n",
    "\n",
    "# === Opening Ergebnisseite ===\n",
    "\n",
    "# This command opens the BA's website from which we want to download all the excel sheets \n",
    "driver.get(\"https://statistik.arbeitsagentur.de/SiteGlobals/Forms/Suche/Einzelheftsuche_Formular.html?topic_f=analyse-gemeldete-arbeitsstellen-kldb2010\")\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# === Accepting Cookie-Banner ===\n",
    "\n",
    "# If we don't deal with the cookies window that automatically opens when opening the website link, our webscraping will not work. The following code adresses \n",
    "# this problem. However, the command still has issues with accepting cookies by itself, so when the cookie window opens you have to manually accept cookies and then the code will run errorless. Except for \n",
    "# accepting cookies, you shoule not do anything in the window while the code is running. Once the command is executed, the window should close automatically. \n",
    "try:\n",
    "    cookie_button = wait.until(EC.element_to_be_clickable((By.ID, \"cc-all\")))\n",
    "    cookie_button.click()\n",
    "    print(\"‚úÖ Cookies akzeptiert.\")\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Kein Cookie-Banner gefunden oder schon geschlossen.\") # This is the response you will get if you accept cookies manually, which you have to do. \n",
    "\n",
    "# === Navigation through all subpages and collection of all Excel-Links ===\n",
    "\n",
    "# The following code browses through all subpages on the website and obtains all links, which initiate the download of excel files\n",
    "\n",
    "all_excel_links = []\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"\\nüîÑ Lade Seite {page_number}...\")\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '.xls')] | //a[contains(@href, '.xlsx')]\")))\n",
    "    except:\n",
    "        print(\"‚ùå Keine Excel-Links gefunden auf dieser Seite.\")\n",
    "        break\n",
    "\n",
    "    elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '.xls')] | //a[contains(@href, '.xlsx')]\")\n",
    "    for el in elements:\n",
    "        href = el.get_attribute(\"href\")\n",
    "        if href and href not in all_excel_links:\n",
    "            all_excel_links.append(href)\n",
    "\n",
    "    # Searching for next subtab and press 'next'\n",
    "    try:\n",
    "        next_link = driver.find_element(By.XPATH, \"//a[contains(@class, 'forward') and contains(@class, 'button')]\")\n",
    "        ActionChains(driver).move_to_element(next_link).perform()\n",
    "        next_link.click()\n",
    "        time.sleep(2)\n",
    "        page_number += 1\n",
    "    except:\n",
    "        print(\"‚úÖ Keine weitere Seite gefunden oder Button deaktiviert.\")\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# === Printing all Excel-Links ===\n",
    "print(f\"\\nüîó Insgesamt {len(all_excel_links)} Excel-Dateien gefunden.\")\n",
    "\n",
    "# === Preparing Download-Folder ===\n",
    "os.makedirs(\"arbeitsagentur_excels\", exist_ok=True)\n",
    "failed_links = []\n",
    "\n",
    "# === Hilfsfunktion: Retry-Logik ===\n",
    "def download_with_retries(url, retries=3, delay=5):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=20)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Versuch {i+1} fehlgeschlagen f√ºr {url}: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "# === Download Excel-Files ===\n",
    "for link in all_excel_links:\n",
    "    filename = link.split(\"/\")[-1].split(\"?\")[0].split(\";\")[0]\n",
    "    filename = urllib.parse.unquote(filename)\n",
    "    filepath = os.path.join(\"arbeitsagentur_excels\", filename)\n",
    "\n",
    "    # Falls Datei schon existiert, √ºberspringen\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"‚è© √úberspringe bereits vorhandene Datei: {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚¨áÔ∏è Lade herunter: {filename}\")\n",
    "    response = download_with_retries(link)\n",
    "    if response:\n",
    "        try:\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"‚úÖ Erfolgreich gespeichert: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler beim Speichern von {filename}: {e}\")\n",
    "            failed_links.append(link)\n",
    "    else:\n",
    "        print(f\"‚ùå Endg√ºltig fehlgeschlagen: {filename}\")\n",
    "        failed_links.append(link)\n",
    "\n",
    "# === Safe all failed links ===\n",
    "if failed_links:\n",
    "    with open(\"failed_excels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for link in failed_links:\n",
    "            f.write(link + \"\\n\")\n",
    "    print(f\"\\n‚ö†Ô∏è {len(failed_links)} Dateien konnten nicht geladen werden. Gespeichert in 'failed_excels.txt'\")\n",
    "else:\n",
    "    print(\"\\nüéâ Alle Excel-Dateien erfolgreich heruntergeladen!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######\n",
    "\n",
    "# 2. Step: Automized download of all pdf files (October 2011 - February 2020) from the BA website (https://statistik.arbeitsagentur.de/SiteGlobals/Forms/Suche/Einzelheftsuche_Formular.html?topic_f=analyse-gemeldete-arbeitsstellen-kldb2010)\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# === Load Packages ===\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "# === Edge Setup ===\n",
    "service = Service(\"C:\\\\Users\\\\jhummels\\\\OneDrive - DIW Berlin\\\\Gehlen, Annica's files - retirement-labor-shortages\\\\edgedriver\\\\msedgedriver.exe\")\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Edge(service=service, options=options)\n",
    "\n",
    "# === Ergebnisseite √∂ffnen ===\n",
    "driver.get(\"https://statistik.arbeitsagentur.de/SiteGlobals/Forms/Suche/Einzelheftsuche_Formular.html?topic_f=analyse-gemeldete-arbeitsstellen-kldb2010\")\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "\n",
    "# === Cookies akzeptieren ===\n",
    "try:\n",
    "    cookie_button = wait.until(EC.element_to_be_clickable((By.ID, \"cc-all\")))\n",
    "    cookie_button.click()\n",
    "    print(\"‚úÖ Cookies akzeptiert.\")\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Kein Cookie-Banner gefunden oder schon geschlossen.\")\n",
    "\n",
    "# === Sammeln aller PDF-Links von allen Seiten ===\n",
    "all_pdf_links = []\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"\\nüîÑ Lade Seite {page_number}...\")\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '.pdf')]\")))\n",
    "    except:\n",
    "        print(\"‚ùå Keine PDF-Links gefunden auf dieser Seite.\")\n",
    "        break\n",
    "\n",
    "    elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '.pdf')]\")\n",
    "    for el in elements:\n",
    "        href = el.get_attribute(\"href\")\n",
    "        if href and href not in all_pdf_links:\n",
    "            all_pdf_links.append(href)\n",
    "\n",
    "    # Weiterbl√§ttern\n",
    "    try:\n",
    "        next_link = driver.find_element(By.XPATH, \"//a[contains(@class, 'forward') and contains(@class, 'button')]\")\n",
    "        ActionChains(driver).move_to_element(next_link).perform()\n",
    "        next_link.click()\n",
    "        time.sleep(2)\n",
    "        page_number += 1\n",
    "    except:\n",
    "        print(\"‚úÖ Keine weitere Seite gefunden oder Button deaktiviert.\")\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# === Ordner vorbereiten ===\n",
    "os.makedirs(\"arbeitsagentur_pdfs\", exist_ok=True)\n",
    "failed_links = []\n",
    "\n",
    "# === Hilfsfunktion: Retry-Logik ===\n",
    "def download_with_retries(url, retries=3, delay=5):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=20)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Versuch {i+1} fehlgeschlagen f√ºr {url}: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "# === PDFs herunterladen ===\n",
    "for link in all_pdf_links:\n",
    "    filename = link.split(\"/\")[-1].split(\"?\")[0].split(\";\")[0]\n",
    "    filename = urllib.parse.unquote(filename)\n",
    "    filepath = os.path.join(\"arbeitsagentur_pdfs\", filename)\n",
    "\n",
    "    # Falls Datei schon existiert, √ºberspringen\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"‚è© √úberspringe bereits vorhandene Datei: {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚¨áÔ∏è Lade herunter: {filename}\")\n",
    "    response = download_with_retries(link)\n",
    "    if response:\n",
    "        try:\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"‚úÖ Erfolgreich gespeichert: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler beim Speichern von {filename}: {e}\")\n",
    "            failed_links.append(link)\n",
    "    else:\n",
    "        print(f\"‚ùå Endg√ºltig fehlgeschlagen: {filename}\")\n",
    "        failed_links.append(link)\n",
    "\n",
    "# === Fehlgeschlagene Links speichern ===\n",
    "if failed_links:\n",
    "    with open(\"failed_pdfs.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for link in failed_links:\n",
    "            f.write(link + \"\\n\")\n",
    "    print(f\"\\n‚ö†Ô∏è {len(failed_links)} Dateien konnten nicht geladen werden. Gespeichert in 'failed_pdfs.txt'\")\n",
    "else:\n",
    "    print(\"\\nüéâ Alle PDFs erfolgreich heruntergeladen!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########\n",
    "\n",
    "# 3. Step: Read all PDF files and extract relevant tables with the Engpass Indicators, then convert the data into a machine readable format (csv, xlsx)\n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "# Input and output folders\n",
    "input_folder = r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\Gehlen, Annica's files - retirement-labor-shortages\\Intern - Work\\arbeitsagentur_pdfs\"\n",
    "output_folder = r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\Gehlen, Annica's files - retirement-labor-shortages\\Intern - Work\\arbeitsagentur_tabellen\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Table detection pattern\n",
    "pattern = re.compile(\n",
    "    r\"(?P<BKZ>\\d{3})\\s+(?P<Beruf>[\\w√§√∂√º√Ñ√ñ√ú√ü\\-,.()\\/&\\s]+?)\\s+\"\n",
    "    r\"(?P<Zugang>[\\d.]+)\\s+(?P<Zugang_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Bestand>[\\d.]+)\\s+(?P<Bestand_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Anteil>[\\d.,]+)\\s+(?P<Anteil_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Vakanzzeit>[\\d.,]+)\\s+(?P<Vakanzzeit_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Arbeitslose>[\\d.]+)\\s+(?P<Arbeitslose_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Relation>[\\d.,]+)\\s+(?P<Relation_V>[-+.,\\d]+)\"\n",
    ")\n",
    "\n",
    "# Loop through all PDFs\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_folder, filename)\n",
    "        doc = fitz.open(pdf_path)\n",
    "\n",
    "        # Extract text from pages likely to contain the table\n",
    "        text = \"\"\n",
    "        for i, page in enumerate(doc):\n",
    "            page_text = page.get_text()\n",
    "            # Look for BKZ + numeric pattern\n",
    "            if re.search(r\"\\b\\d{3}\\s+[A-Za-z√Ñ√ñ√ú√§√∂√º√ü]\", page_text) and re.search(r\"\\d+\\s+[-+,.0-9]+\\s+\\d+\", page_text):\n",
    "                text += page_text + \"\\n\"\n",
    "\n",
    "        # Match rows using regex\n",
    "        rows = []\n",
    "        for match in pattern.finditer(text):\n",
    "            row = match.groupdict()\n",
    "            for key in row:\n",
    "                row[key] = row[key].replace(\".\", \"\").replace(\",\", \".\") if key != \"Beruf\" else row[key].strip()\n",
    "            rows.append(row)\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows)\n",
    "            for col in df.columns:\n",
    "                if col != \"Beruf\":\n",
    "                    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "            # Save CSV\n",
    "            output_path = os.path.join(output_folder, os.path.splitext(filename)[0] + \".csv\")\n",
    "            df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úì Saved: {output_path}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No table found in: {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Skipping file with unexpected name: combined_arbeitsagentur_data.csv\n",
      "‚úì Combined CSV saved to: C:\\Users\\jhummels\\OneDrive - DIW Berlin\\Gehlen, Annica's files - retirement-labor-shortages\\Intern - Work\\arbeitsagentur_tabellen\\combined_arbeitsagentur_data.csv\n",
      "‚úì Combined Excel saved to: C:\\Users\\jhummels\\OneDrive - DIW Berlin\\Gehlen, Annica's files - retirement-labor-shortages\\Intern - Work\\arbeitsagentur_tabellen\\combined_arbeitsagentur_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########\n",
    "\n",
    "# 4. Merge all tables extracted from pdfs into one data frame and add a year and bundesland column based on their file name\n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Folder with individual CSVs\n",
    "csv_folder = r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\Gehlen, Annica's files - retirement-labor-shortages\\Intern - Work\\arbeitsagentur_tabellen\"\n",
    "\n",
    "# List to collect all dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Regex to extract Bundesland and date info\n",
    "filename_pattern = re.compile(r\"kldb2010-(\\d{2})-0-(\\d{6})\")\n",
    "\n",
    "for file in os.listdir(csv_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        match = filename_pattern.search(file)\n",
    "        if match:\n",
    "            bundesland = match.group(1)\n",
    "            year = match.group(2)[:4]\n",
    "            month = match.group(2)[4:]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping file with unexpected name: {file}\")\n",
    "            continue\n",
    "\n",
    "        # Load CSV and add metadata\n",
    "        file_path = os.path.join(csv_folder, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"Bundesland\"] = bundesland\n",
    "        df[\"Year\"] = int(year)\n",
    "        df[\"Month\"] = int(month)\n",
    "        all_dfs.append(df)\n",
    "\n",
    "# Merge all\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Export\n",
    "output_csv = os.path.join(csv_folder, \"combined_arbeitsagentur_data.csv\")\n",
    "output_excel = os.path.join(csv_folder, \"combined_arbeitsagentur_data.xlsx\")\n",
    "\n",
    "combined_df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "combined_df.to_excel(output_excel, index=False)\n",
    "\n",
    "print(f\"‚úì Combined CSV saved to: {output_csv}\")\n",
    "print(f\"‚úì Combined Excel saved to: {output_excel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########\n",
    "\n",
    "# 5. Clean PDF data frame and get rid of little inaccuracies \n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re  # <-- Add this\n",
    "\n",
    "data = combined_df.copy()\n",
    "\n",
    "# Show all rows\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "\n",
    "# Optional: also widen column display if needed\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Keep only rows where BKZ is a proper 3-digit number between 100 and 999\n",
    "data = data[data[\"BKZ\"].astype(str).str.fullmatch(r\"\\d{3}\")]\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_clean_bkz_and_beruf(row):\n",
    "    beruf_raw = str(row.get(\"Beruf\", \"\")).replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    # Match pattern like: \"814 Human- und Zahnmedizin\" (ignore any garbage before it)\n",
    "    match = re.search(r\"(\\d{3})\\s+([A-Z√Ñ√ñ√úa-z√§√∂√º√ü].+)\", beruf_raw)\n",
    "    if match:\n",
    "        row[\"BKZ\"] = match.group(1)\n",
    "        row[\"Beruf\"] = match.group(2).strip()\n",
    "    return row\n",
    "\n",
    "data = data.apply(extract_clean_bkz_and_beruf, axis=1)\n",
    "# Keep rows where Beruf starts with a letter (i.e., likely a real label)\n",
    "data = data[\n",
    "    data[\"Beruf\"].notna() &\n",
    "    data[\"Beruf\"].astype(str).str.match(r\"^[A-Z√Ñ√ñ√úa-z√§√∂√º√ü]\")\n",
    "]\n",
    "\n",
    "# Clean up whitespace and hidden characters in all string columns\n",
    "for col in [\"BKZ\", \"Beruf\", \"Bundesland\"]:\n",
    "    data[col] = data[col].astype(str).str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n",
    "data = data.drop_duplicates(subset=[\"BKZ\", \"Beruf\", \"Bundesland\", \"Year\", \"Month\"], keep=\"first\")\n",
    "\n",
    "\n",
    "\n",
    "data.head(2000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "\n",
    "# 6. Rename columns of PDF data to match column names of the Excel Data \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = data.rename(columns={\n",
    "    \"Anteil\": \"3_Monate_Vakant_Anteil\",\n",
    "    \"Anteil_V\" : \"3_Monate_Vakant_V_abs\",\n",
    "    \"Vakanzzeit\" : \"abgesch_Vakanzzeit_Tage\",\n",
    "    \"Vakanzzeit_V\" : \"abgesch_Vakanzzeit_V_abs\"\n",
    "})\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######\n",
    "\n",
    "# 7. Clean and Improve format of Excel Data Frame, then merge all excel data frames into one \n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Path to folder with Excel files\n",
    "excel_folder = r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\Gehlen, Annica's files - retirement-labor-shortages\\Intern - Work\\arbeitsagentur_excels\"\n",
    "\n",
    "# Collect cleaned DataFrames\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through Excel files\n",
    "for file in os.listdir(excel_folder):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        filepath = os.path.join(excel_folder, file)\n",
    "        try:\n",
    "            # Load the sheet (header on row 7)\n",
    "            df = pd.read_excel(filepath, sheet_name=\"3.1 Engpass_Tab1\", header=7)\n",
    "\n",
    "            # Drop last 4 columns\n",
    "            df = df.iloc[:, :-4]\n",
    "\n",
    "            # Rename columns (up to 24)\n",
    "            df.columns = [\n",
    "             \"Drop\", \"Beruf\",\n",
    "             \"Zugang\", \"Zugang_V\",\n",
    "             \"Bestand\", \"Bestand_V\",\n",
    "             \"3_Monate_Vakant_abs\", \"3_Monate_Vakant_V\",\n",
    "             \"3_Monate_Vakant_Anteil\", \"3_Monate_Vakant_V_abs\",\n",
    "             \"abgesch_Vakanzzeit_Tage\", \"abgesch_Vakanzzeit_V_abs\",\n",
    "             \"Arbeitslose\", \"Arbeitslose_V\",\n",
    "             \"SGBIII_abs\", \"SGBIII_V\",\n",
    "             \"SGBII_abs\", \"SGBII_V\",\n",
    "             \"Relation\", \"Relation_V\",\n",
    "             \"SGBIII_abs_2\", \"SGBIII_V_2\",\n",
    "             \"SGBII_abs_2\", \"SGBII_V_2\"\n",
    "            ]\n",
    "\n",
    "            # Drop the first column (empty)\n",
    "            df = df.drop(columns=\"Drop\")\n",
    "\n",
    "            # Remove footer or malformed rows\n",
    "            df = df[df[\"Beruf\"].astype(str).str.match(r\"^\\d{3}\\s+.+\")]\n",
    "\n",
    "            # Split BKZ from Beruf\n",
    "            df[[\"BKZ\", \"Beruf\"]] = df[\"Beruf\"].str.extract(r\"^(\\d{3})\\s+(.+)$\")\n",
    "\n",
    "            # Convert numeric columns\n",
    "            numeric_cols = [col for col in df.columns if col not in [\"Beruf\", \"BKZ\"] and df[col].ndim == 1]\n",
    "            for col in numeric_cols:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "            # Drop \"Insgesamt\" row if present\n",
    "            df = df[~df.iloc[:, 1].astype(str).str.contains(\"Insgesamt\", na=False)]\n",
    "\n",
    "            # Add metadata from filename\n",
    "            match = re.search(r\"kldb2010-(\\d{2})-0-(\\d{6})\", file)\n",
    "            if match:\n",
    "                df[\"Bundesland\"] = match.group(1)\n",
    "                df[\"Year\"] = int(match.group(2)[:4])\n",
    "                df[\"Month\"] = int(match.group(2)[4:])\n",
    "            else:\n",
    "                df[\"Bundesland\"] = df[\"Year\"] = df[\"Month\"] = None\n",
    "\n",
    "            df[\"source_file\"] = file\n",
    "\n",
    "            all_dfs.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {file}: {e}\")\n",
    "\n",
    "# Combine all cleaned data\n",
    "combined_excel_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Preview\n",
    "print(f\"‚úì Combined {len(all_dfs)} files. Total rows: {combined_excel_df.shape[0]}\")\n",
    "combined_excel_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the combinded excel data fram \n",
    "\n",
    "combined_excel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inquire NA count for the PDF and Excel Data Frame\n",
    "\n",
    "\n",
    "print(data.isna().sum())\n",
    "print(combined_excel_df.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SGBIII_abs, SGBIII_V, SGBII_abs, SGBII_V all have 59452 missing values (which are all rows), so we can drop them without any bad conscience \n",
    "\n",
    "\n",
    "combined_excel_df = combined_excel_df.drop(columns=[\n",
    "    \"SGBIII_abs\", \"SGBIII_V\", \"SGBII_abs\", \"SGBII_V\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BKZ',\n",
       " 'Beruf',\n",
       " 'Zugang',\n",
       " 'Zugang_V',\n",
       " 'Bestand',\n",
       " 'Bestand_V',\n",
       " '3_Monate_Vakant_Anteil',\n",
       " '3_Monate_Vakant_V_abs',\n",
       " 'abgesch_Vakanzzeit_Tage',\n",
       " 'abgesch_Vakanzzeit_V_abs',\n",
       " 'Arbeitslose',\n",
       " 'Arbeitslose_V',\n",
       " 'Relation',\n",
       " 'Relation_V',\n",
       " 'Bundesland',\n",
       " 'Year',\n",
       " 'Month']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beruf',\n",
       " 'Zugang',\n",
       " 'Zugang_V',\n",
       " 'Bestand',\n",
       " 'Bestand_V',\n",
       " '3_Monate_Vakant_abs',\n",
       " '3_Monate_Vakant_V',\n",
       " '3_Monate_Vakant_Anteil',\n",
       " '3_Monate_Vakant_V_abs',\n",
       " 'abgesch_Vakanzzeit_Tage',\n",
       " 'abgesch_Vakanzzeit_V_abs',\n",
       " 'Arbeitslose',\n",
       " 'Arbeitslose_V',\n",
       " 'Relation',\n",
       " 'Relation_V',\n",
       " 'SGBIII_abs_2',\n",
       " 'SGBIII_V_2',\n",
       " 'SGBII_abs_2',\n",
       " 'SGBII_V_2',\n",
       " 'BKZ',\n",
       " 'Bundesland',\n",
       " 'Year',\n",
       " 'Month',\n",
       " 'source_file']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(combined_excel_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149419, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beruf</th>\n",
       "      <th>Zugang</th>\n",
       "      <th>Zugang_V</th>\n",
       "      <th>Bestand</th>\n",
       "      <th>Bestand_V</th>\n",
       "      <th>3_Monate_Vakant_abs</th>\n",
       "      <th>3_Monate_Vakant_V</th>\n",
       "      <th>3_Monate_Vakant_Anteil</th>\n",
       "      <th>3_Monate_Vakant_V_abs</th>\n",
       "      <th>abgesch_Vakanzzeit_Tage</th>\n",
       "      <th>abgesch_Vakanzzeit_V_abs</th>\n",
       "      <th>Arbeitslose</th>\n",
       "      <th>Arbeitslose_V</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Relation_V</th>\n",
       "      <th>SGBIII_abs_2</th>\n",
       "      <th>SGBIII_V_2</th>\n",
       "      <th>SGBII_abs_2</th>\n",
       "      <th>SGBII_V_2</th>\n",
       "      <th>BKZ</th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human- und Zahnmedizin</td>\n",
       "      <td>147</td>\n",
       "      <td>10.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.3</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>167.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>814</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Werbung und Marketing</td>\n",
       "      <td>1949</td>\n",
       "      <td>4.2</td>\n",
       "      <td>595.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>921</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Altenpflege</td>\n",
       "      <td>1644</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>561.0</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>821</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Versicherungs- u. Finanzdienstleistungen</td>\n",
       "      <td>437</td>\n",
       "      <td>6.8</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>102.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>368.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>721</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.</td>\n",
       "      <td>1563</td>\n",
       "      <td>24.9</td>\n",
       "      <td>453.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>813</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Beruf  Zugang  Zugang_V  Bestand  \\\n",
       "0                    Human- und Zahnmedizin     147      10.5     66.0   \n",
       "1                     Werbung und Marketing    1949       4.2    595.0   \n",
       "2                               Altenpflege    1644     -13.5    561.0   \n",
       "3  Versicherungs- u. Finanzdienstleistungen     437       6.8    136.0   \n",
       "4  Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.    1563      24.9    453.0   \n",
       "\n",
       "   Bestand_V  3_Monate_Vakant_abs  3_Monate_Vakant_V  3_Monate_Vakant_Anteil  \\\n",
       "0       -1.4                  NaN                NaN                    48.3   \n",
       "1       17.4                  NaN                NaN                    46.5   \n",
       "2       -3.6                  NaN                NaN                    50.6   \n",
       "3       -5.6                  NaN                NaN                    42.8   \n",
       "4       17.9                  NaN                NaN                    38.8   \n",
       "\n",
       "   3_Monate_Vakant_V_abs  abgesch_Vakanzzeit_Tage  abgesch_Vakanzzeit_V_abs  \\\n",
       "0                   -4.7                    167.0                      50.0   \n",
       "1                    5.4                    113.0                      29.0   \n",
       "2                    5.3                    110.0                      13.0   \n",
       "3                    1.9                    102.0                       6.0   \n",
       "4                   -3.0                     87.0                     -17.0   \n",
       "\n",
       "   Arbeitslose  Arbeitslose_V  Relation  Relation_V  SGBIII_abs_2  SGBIII_V_2  \\\n",
       "0         93.0           -9.4     140.0       -12.0           NaN         NaN   \n",
       "1        783.0           -1.0     132.0       -24.0           NaN         NaN   \n",
       "2        748.0          -25.4     133.0       -39.0           NaN         NaN   \n",
       "3        500.0          -10.6     368.0       -20.0           NaN         NaN   \n",
       "4        708.0           -6.2     156.0       -40.0           NaN         NaN   \n",
       "\n",
       "   SGBII_abs_2  SGBII_V_2  BKZ Bundesland  Year  Month source_file  \n",
       "0          NaN        NaN  814         01  2011     10         NaN  \n",
       "1          NaN        NaN  921         01  2011     10         NaN  \n",
       "2          NaN        NaN  821         01  2011     10         NaN  \n",
       "3          NaN        NaN  721         01  2011     10         NaN  \n",
       "4          NaN        NaN  813         01  2011     10         NaN  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Reindex `data` to match the column structure of `combined_excel_df`\n",
    "data_aligned = data.reindex(columns=combined_excel_df.columns)\n",
    "\n",
    "# Append older `data` before `combined_excel_df`\n",
    "full_df = pd.concat([data_aligned, combined_excel_df], ignore_index=True)\n",
    "\n",
    "# Preview result\n",
    "print(full_df.shape)\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>BKZ</th>\n",
       "      <th>Beruf</th>\n",
       "      <th>Zugang</th>\n",
       "      <th>Zugang_V</th>\n",
       "      <th>Bestand</th>\n",
       "      <th>Bestand_V</th>\n",
       "      <th>3_Monate_Vakant_abs</th>\n",
       "      <th>3_Monate_Vakant_V</th>\n",
       "      <th>3_Monate_Vakant_Anteil</th>\n",
       "      <th>3_Monate_Vakant_V_abs</th>\n",
       "      <th>abgesch_Vakanzzeit_Tage</th>\n",
       "      <th>abgesch_Vakanzzeit_V_abs</th>\n",
       "      <th>Arbeitslose</th>\n",
       "      <th>Arbeitslose_V</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Relation_V</th>\n",
       "      <th>SGBIII_abs_2</th>\n",
       "      <th>SGBIII_V_2</th>\n",
       "      <th>SGBII_abs_2</th>\n",
       "      <th>SGBII_V_2</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>814</td>\n",
       "      <td>Human- und Zahnmedizin</td>\n",
       "      <td>147</td>\n",
       "      <td>10.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.3</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>167.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>921</td>\n",
       "      <td>Werbung und Marketing</td>\n",
       "      <td>1949</td>\n",
       "      <td>4.2</td>\n",
       "      <td>595.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>821</td>\n",
       "      <td>Altenpflege</td>\n",
       "      <td>1644</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>561.0</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>721</td>\n",
       "      <td>Versicherungs- u. Finanzdienstleistungen</td>\n",
       "      <td>437</td>\n",
       "      <td>6.8</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>102.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>368.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>813</td>\n",
       "      <td>Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.</td>\n",
       "      <td>1563</td>\n",
       "      <td>24.9</td>\n",
       "      <td>453.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Bundesland  Year  Month  BKZ                                     Beruf  \\\n",
       "0         01  2011     10  814                    Human- und Zahnmedizin   \n",
       "1         01  2011     10  921                     Werbung und Marketing   \n",
       "2         01  2011     10  821                               Altenpflege   \n",
       "3         01  2011     10  721  Versicherungs- u. Finanzdienstleistungen   \n",
       "4         01  2011     10  813  Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.   \n",
       "\n",
       "   Zugang  Zugang_V  Bestand  Bestand_V  3_Monate_Vakant_abs  \\\n",
       "0     147      10.5     66.0       -1.4                  NaN   \n",
       "1    1949       4.2    595.0       17.4                  NaN   \n",
       "2    1644     -13.5    561.0       -3.6                  NaN   \n",
       "3     437       6.8    136.0       -5.6                  NaN   \n",
       "4    1563      24.9    453.0       17.9                  NaN   \n",
       "\n",
       "   3_Monate_Vakant_V  3_Monate_Vakant_Anteil  3_Monate_Vakant_V_abs  \\\n",
       "0                NaN                    48.3                   -4.7   \n",
       "1                NaN                    46.5                    5.4   \n",
       "2                NaN                    50.6                    5.3   \n",
       "3                NaN                    42.8                    1.9   \n",
       "4                NaN                    38.8                   -3.0   \n",
       "\n",
       "   abgesch_Vakanzzeit_Tage  abgesch_Vakanzzeit_V_abs  Arbeitslose  \\\n",
       "0                    167.0                      50.0         93.0   \n",
       "1                    113.0                      29.0        783.0   \n",
       "2                    110.0                      13.0        748.0   \n",
       "3                    102.0                       6.0        500.0   \n",
       "4                     87.0                     -17.0        708.0   \n",
       "\n",
       "   Arbeitslose_V  Relation  Relation_V  SGBIII_abs_2  SGBIII_V_2  SGBII_abs_2  \\\n",
       "0           -9.4     140.0       -12.0           NaN         NaN          NaN   \n",
       "1           -1.0     132.0       -24.0           NaN         NaN          NaN   \n",
       "2          -25.4     133.0       -39.0           NaN         NaN          NaN   \n",
       "3          -10.6     368.0       -20.0           NaN         NaN          NaN   \n",
       "4           -6.2     156.0       -40.0           NaN         NaN          NaN   \n",
       "\n",
       "   SGBII_V_2 source_file  \n",
       "0        NaN         NaN  \n",
       "1        NaN         NaN  \n",
       "2        NaN         NaN  \n",
       "3        NaN         NaN  \n",
       "4        NaN         NaN  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust column names in a better order\n",
    "\n",
    "\n",
    "desired_order = [\n",
    "    'Bundesland', 'Year', 'Month',\n",
    "    'BKZ', 'Beruf',\n",
    "    'Zugang', 'Zugang_V',\n",
    "    'Bestand', 'Bestand_V',\n",
    "    '3_Monate_Vakant_abs', '3_Monate_Vakant_V',\n",
    "    '3_Monate_Vakant_Anteil', '3_Monate_Vakant_V_abs',\n",
    "    'abgesch_Vakanzzeit_Tage', 'abgesch_Vakanzzeit_V_abs',\n",
    "    'Arbeitslose', 'Arbeitslose_V',\n",
    "    'Relation', 'Relation_V',\n",
    "    'SGBIII_abs_2', 'SGBIII_V_2',\n",
    "    'SGBII_abs_2', 'SGBII_V_2',\n",
    "    'source_file'\n",
    "]\n",
    "\n",
    "# Keep only the columns that are actually in the DataFrame\n",
    "existing_columns = [col for col in desired_order if col in full_df.columns]\n",
    "\n",
    "# Reorder\n",
    "full_df = full_df[existing_columns]\n",
    "\n",
    "\n",
    "full_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfull_df\u001b[49m.to_excel(\u001b[33m\"\u001b[39m\u001b[33marbeitsagentur_full_data.xlsx\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "full_df.to_excel(\"arbeitsagentur_full_data.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
